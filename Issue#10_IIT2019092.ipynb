{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv16qOa_9nqo"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import inception_v3\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import cv2,os\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBUBVUTbGrwp",
        "outputId": "261dd610-5d7e-43b9-ade9-40fdd6f73c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "\n",
        "data_path='/content/drive/My Drive/dataset (1)'\n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'with_mask': 0, 'without_mask': 1}\n",
            "['with_mask', 'without_mask']\n",
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pHQyHXmIcLb"
      },
      "source": [
        "img_size=100\n",
        "data=[]\n",
        "target=[]\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "        \n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "\n",
        "        try:\n",
        "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n",
        "            #Coverting the image into gray scale\n",
        "            resized=cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the gray scale into 50x50, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR0QWCx0Idzb"
      },
      "source": [
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target=np.array(target)\n",
        "new_target=np_utils.to_categorical(target)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "insy8TL4n5NK"
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "target = lb.fit_transform(target)\n",
        "target = to_categorical(target)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHJoP-A8apf7"
      },
      "source": [
        "np.save('data',data)\n",
        "np.save('target',new_target)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQK_UHdWaqo6"
      },
      "source": [
        "data=np.load('data.npy')\n",
        "target=np.load('target.npy')\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruO91o6Ad5D9"
      },
      "source": [
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The first CNN layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Conv2D(100,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The second convolution layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "#Flatten layer to stack the output convolutions from second convolution layer\n",
        "model.add(Dense(50,activation='relu'))\n",
        "#Dense layer of 64 neurons\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "#The Final layer with two outputs for two categories\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AsxPyh4eyR0"
      },
      "source": [
        "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trrAzuCYeyIN",
        "outputId": "6e88fc25-0d56-4974-a512-fbcb80a9c752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
        "history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.6719INFO:tensorflow:Assets written to: model-001.model/assets\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.6048 - accuracy: 0.6719 - val_loss: 0.4600 - val_accuracy: 0.8015\n",
            "Epoch 2/20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.8157INFO:tensorflow:Assets written to: model-002.model/assets\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.4093 - accuracy: 0.8157 - val_loss: 0.3467 - val_accuracy: 0.8493\n",
            "Epoch 3/20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.8848INFO:tensorflow:Assets written to: model-003.model/assets\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.2896 - accuracy: 0.8848 - val_loss: 0.2827 - val_accuracy: 0.8971\n",
            "Epoch 4/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.2188 - accuracy: 0.9115 - val_loss: 0.3012 - val_accuracy: 0.8934\n",
            "Epoch 5/20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9346INFO:tensorflow:Assets written to: model-005.model/assets\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.1772 - accuracy: 0.9346 - val_loss: 0.2491 - val_accuracy: 0.9154\n",
            "Epoch 6/20\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.1310 - accuracy: 0.9539 - val_loss: 0.2543 - val_accuracy: 0.9007\n",
            "Epoch 7/20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9447INFO:tensorflow:Assets written to: model-007.model/assets\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.1479 - accuracy: 0.9447 - val_loss: 0.2307 - val_accuracy: 0.9081\n",
            "Epoch 8/20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9594INFO:tensorflow:Assets written to: model-008.model/assets\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.1159 - accuracy: 0.9594 - val_loss: 0.2131 - val_accuracy: 0.9154\n",
            "Epoch 9/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0688 - accuracy: 0.9724 - val_loss: 0.2893 - val_accuracy: 0.9228\n",
            "Epoch 10/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0847 - accuracy: 0.9687 - val_loss: 0.2184 - val_accuracy: 0.9301\n",
            "Epoch 11/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0708 - accuracy: 0.9687 - val_loss: 0.2198 - val_accuracy: 0.9301\n",
            "Epoch 12/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0514 - accuracy: 0.9862 - val_loss: 0.3168 - val_accuracy: 0.9265\n",
            "Epoch 13/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.2432 - val_accuracy: 0.9338\n",
            "Epoch 14/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.3104 - val_accuracy: 0.9118\n",
            "Epoch 15/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0506 - accuracy: 0.9779 - val_loss: 0.2735 - val_accuracy: 0.8971\n",
            "Epoch 16/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0772 - accuracy: 0.9724 - val_loss: 0.2720 - val_accuracy: 0.9081\n",
            "Epoch 17/20\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.0349 - accuracy: 0.9908 - val_loss: 0.3293 - val_accuracy: 0.9118\n",
            "Epoch 18/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.3247 - val_accuracy: 0.9338\n",
            "Epoch 19/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0876 - accuracy: 0.9631 - val_loss: 0.2269 - val_accuracy: 0.9301\n",
            "Epoch 20/20\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 0.2548 - val_accuracy: 0.9228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv0yHxtilt8W",
        "outputId": "220dc39c-9725-4e77-eb25-cfbd23ce98bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "predIdxs = model.predict(test_data, batch_size=32)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(classification_report(test_target.argmax(axis=1), predIdxs, target_names=['With Mask', 'Without Mask']))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   With Mask       0.99      0.96      0.97        72\n",
            "Without Mask       0.96      0.99      0.97        79\n",
            "\n",
            "    accuracy                           0.97       151\n",
            "   macro avg       0.97      0.97      0.97       151\n",
            "weighted avg       0.97      0.97      0.97       151\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}